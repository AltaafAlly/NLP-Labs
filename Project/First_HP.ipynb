{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRJrviVcUiwP"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import requests\n",
        "import lzma\n",
        "import os\n",
        "from datasets import Dataset, DatasetDict\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, TrainingArguments, DataCollatorForLanguageModeling, Trainer\n",
        "import numpy as np\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OqQpKiBn99gc"
      },
      "outputs": [],
      "source": [
        "# url = \"http://data.statmt.org/cc-100/sw.txt.xz\"\n",
        "# file_name = \"sw.txt.xz\"\n",
        "# response = requests.get(url, stream=True)\n",
        "# with open(file_name, \"wb\") as file:\n",
        "#     for chunk in response.iter_content(chunk_size=1024):\n",
        "#         if chunk:\n",
        "#             file.write(chunk)\n",
        "# print(f\"Downloaded {file_name}\")\n",
        "\n",
        "# output_file = \"sw.txt\"\n",
        "# with lzma.open(file_name, \"rb\") as compressed_file:\n",
        "#     with open(output_file, \"wb\") as extracted_file:\n",
        "#         extracted_file.write(compressed_file.read())\n",
        "# print(f\"Extracted to {output_file}\")\n",
        "# os.remove(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1wmT3_8K_e80"
      },
      "outputs": [],
      "source": [
        "# Step 2: Read and prepare data\n",
        "num_lines_to_read = 100000  # Adjust this as needed\n",
        "text_data = []\n",
        "with open('/datasets/mdawood/sw.txt', 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i < num_lines_to_read:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                text_data.append(line)\n",
        "        else:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8tnLDRHC_k8f"
      },
      "outputs": [],
      "source": [
        "# Create dataset\n",
        "data_dict = {'text': text_data}\n",
        "dataset = Dataset.from_dict(data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LZATSmZX_nGL"
      },
      "outputs": [],
      "source": [
        "# Clean text\n",
        "def clean_text(example):\n",
        "    text = example['text']\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-ZäöüÄÖÜßẞ\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = text.lower()\n",
        "    return {'text': text}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po1DTUBI_o4T"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(clean_text)\n",
        "dataset = dataset.shuffle(seed=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M6VN2-2q_r5f"
      },
      "outputs": [],
      "source": [
        "# Split dataset (80% train, 10% validation, 10% test)\n",
        "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "test_valid = split_dataset['test'].train_test_split(test_size=0.5, seed=42)\n",
        "swahili_dataset = DatasetDict({\n",
        "    'train': split_dataset['train'],\n",
        "    'validation': test_valid['train'],\n",
        "    'test': test_valid['test'],\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7knEqRJb_tlP"
      },
      "outputs": [],
      "source": [
        "# Print the number of samples in each split\n",
        "print(f\"Number of samples in train: {len(swahili_dataset['train'])}\")\n",
        "print(f\"Number of samples in validation: {len(swahili_dataset['validation'])}\")\n",
        "print(f\"Number of samples in test: {len(swahili_dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF4EdlvM_vjC"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    return tokenizer(batch['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "tokenized_datasets = swahili_dataset.map(tokenize_function, batched=True, num_proc=4)\n",
        "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8AhpBRZ_3bD"
      },
      "outputs": [],
      "source": [
        "# Pre-trained model loading\n",
        "def model_init():\n",
        "    return AutoModelForMaskedLM.from_pretrained('xlm-roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nOn-tBPBAEvp"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCDDjd81V_gs"
      },
      "outputs": [],
      "source": [
        "# Training arguments (initial, can be overwritten by hyperparameter search)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='no',  # Avoid saving too many models during hyperparameter search\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        "    report_to=['none'],  # Disable reporting to external services\n",
        "    disable_tqdm=True,  # Disable tqdm to reduce output during hyperparameter search\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q_4VWtS2V8Jw"
      },
      "outputs": [],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter search space\n",
        "def hp_space(trial):\n",
        "    return {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
        "        'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.1),\n",
        "        'per_device_train_batch_size': trial.suggest_categorical(\n",
        "            'per_device_train_batch_size', [8, 16, 32]\n",
        "        ),\n",
        "        'num_train_epochs': trial.suggest_int('num_train_epochs', 2, 4),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Objective function for Optuna\n",
        "def model_objective(trial):\n",
        "    # Set hyperparameters\n",
        "    args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        overwrite_output_dir=True,\n",
        "        evaluation_strategy='epoch',\n",
        "        learning_rate=trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
        "        per_device_train_batch_size=trial.suggest_categorical(\n",
        "            'per_device_train_batch_size', [8, 16, 32]\n",
        "        ),\n",
        "        num_train_epochs=trial.suggest_int('num_train_epochs', 2, 4),\n",
        "        weight_decay=trial.suggest_float('weight_decay', 0.0, 0.1),\n",
        "        save_total_limit=1,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=500,\n",
        "        report_to=['none'],\n",
        "        disable_tqdm=True,\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer with the trial's hyperparameters\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_datasets['train'],\n",
        "        eval_dataset=tokenized_datasets['validation'],\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_results = trainer.evaluate()\n",
        "    perplexity = np.exp(eval_results['eval_loss'])\n",
        "    return perplexity  # Objective is to minimize perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run hyperparameter search\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(model_objective, n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters:\", study.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update training arguments with best hyperparameters\n",
        "best_params = study.best_trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
        "    num_train_epochs=best_params['num_train_epochs'],\n",
        "    weight_decay=best_params['weight_decay'],\n",
        "    save_total_limit=2,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=500,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Trainer with best hyperparameters\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# %%\n",
        "# Train the model with best hyperparameters\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "eval_results_after = trainer.evaluate()\n",
        "perplexity_after = np.exp(eval_results_after['eval_loss'])\n",
        "print(f\"Perplexity after fine-tuning: {perplexity_after:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "eval_results_test = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
        "perplexity_test = np.exp(eval_results_test['eval_loss'])\n",
        "print(f\"Perplexity on test set: {perplexity_test:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Print best hyperparameters\n",
        "# print(\"Best hyperparameters:\", study.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5OeWaGxAHk7"
      },
      "outputs": [],
      "source": [
        "# # Step 4: Evaluate pre-trained model (before fine-tuning)\n",
        "# eval_results_before = trainer_before.evaluate()\n",
        "# perplexity_before = np.exp(eval_results_before['eval_loss'])\n",
        "# print(f\"Perplexity before fine-tuning: {perplexity_before:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wvRU5ovUiwT"
      },
      "outputs": [],
      "source": [
        "# Step 5: Fine-tune the model on Swahili dataset\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir='./results',\n",
        "#     overwrite_output_dir=True,\n",
        "#     evaluation_strategy='epoch',\n",
        "#     learning_rate=5e-5,\n",
        "#     per_device_train_batch_size=8,\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     save_total_limit=2,\n",
        "#     logging_dir='./logs',\n",
        "#     logging_steps=500,\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=tokenized_datasets['train'],\n",
        "#     eval_dataset=tokenized_datasets['validation'],\n",
        "#     data_collator=data_collator,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "5qqj-NobAJkS",
        "outputId": "91775c15-fcf8-4dcf-eba4-75b351e411fe"
      },
      "outputs": [],
      "source": [
        "# trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6188UQzMJ_l"
      },
      "outputs": [],
      "source": [
        "# # Step 6: Calculate perplexity after fine-tuning\n",
        "# eval_results_after = trainer.evaluate()\n",
        "# perplexity_after = np.exp(eval_results_after['eval_loss'])\n",
        "# print(f\"Perplexity after fine-tuning: {perplexity_after:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Cubx_MM5jT"
      },
      "outputs": [],
      "source": [
        "# # Step 7: Save the fine-tuned model\n",
        "# trainer.save_model('./swahili-xlmr-finetuned')\n",
        "# tokenizer.save_pretrained('./swahili-xlmr-finetuned')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
